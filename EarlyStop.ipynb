{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN7KIsZ3F_S-"
      },
      "source": [
        "# **Section 1 : Importing necessary files**\n",
        "\n",
        "\n",
        "\n",
        "*   The 'train_loss.csv' file has an additional row which consist of batch_name, that is omitted\n",
        "*   The first four columns in all the data files represent the vlaues for the hyperparamaters, they are also omitted as they are taken from the 'HP_space.csv'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Mfcv-OpBFb6M",
        "outputId": "52e65da0-5fce-4340-bf61-eac8acff26d5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "hp_values = pd.read_csv('HP_space.csv')\n",
        "train_loss = pd.read_csv('train_loss.csv').iloc[1:,4:]\n",
        "eval_loss = pd.read_csv('eval_loss.csv').iloc[:,4:]\n",
        "eval_acc = pd.read_csv('eval_acc.csv').iloc[:,4:]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kOzmgayL9NI"
      },
      "source": [
        "# **Section 2 : Handling Missing Values**\n",
        "\n",
        "To handle missing values in the data files, NaN values are replaced with the mean of the column containing the respective NaN value.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "T7lPF3u0iCe-"
      },
      "outputs": [],
      "source": [
        "def handleNaN(data):\n",
        "  for col in data.columns:\n",
        "    mean_value = data[col].astype(float).mean()\n",
        "    data[col].fillna(mean_value, inplace=True)\n",
        "\n",
        "  return data\n",
        "\n",
        "train_loss = handleNaN(train_loss)\n",
        "eval_loss = handleNaN(eval_loss)\n",
        "eval_acc = handleNaN(eval_acc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_7WzPBfYIfmz"
      },
      "outputs": [],
      "source": [
        "train_records = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98, 100, 102, 104, 106, 108, 110, 112, 114, 116, 118, 120, 122, 124, 126, 128, 130, 132, 134, 136, 138, 140, 142, 144, 146, 148, 150, 152, 154, 156, 158, 160, 162, 164, 166, 168, 170, 172, 174, 176, 178, 180, 182, 184, 186, 188, 190, 192, 194, 196, 198, 200, 202]\n",
        "val_records= [3, 7, 11, 15, 19, 23, 27, 31, 35, 39, 43, 47, 51, 55, 59, 63, 67, 71, 75, 79, 83, 87, 91, 95, 99, 103, 107, 111, 115, 119, 123, 127, 131, 135, 139, 143, 147, 151, 155, 159, 163, 167, 171, 175, 179, 183, 187, 191, 195, 199]\n",
        "test_records= [5, 9, 13, 17, 21, 25, 29, 33, 37, 41, 45, 49, 53, 57, 61, 65, 69, 73, 77, 81, 85, 89, 93, 97, 101, 105, 109, 113, 117, 121, 125, 129, 133, 137, 141, 145, 149, 153, 157, 161, 165, 169, 173, 177, 181, 185, 189, 193, 197, 201]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZpukyuNJNHX"
      },
      "source": [
        "# **Section 3:Dataset Generation**\n",
        "Here, we generate the training, validation and testing dataset according the value of E provided to the function generate_dataset(E)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CFn7aascHY3r"
      },
      "outputs": [],
      "source": [
        "def generate_dataset(E):\n",
        "\n",
        "  #number of epochs for which the values have to be considered\n",
        "  M = 150\n",
        "\n",
        "  def create_dataset(data_records):\n",
        "    dataset = pd.DataFrame()\n",
        "    for record_index in data_records:\n",
        "      hyperparameters = hp_values.iloc[record_index-1,:]\n",
        "      train_loss_values = train_loss.iloc[record_index-1,0:E*50]\n",
        "      eval_loss_values = eval_loss.iloc[record_index-1,0:E]\n",
        "      eval_acc_values = eval_acc.iloc[record_index-1,0:E]\n",
        "      M_value = pd.Series([M])\n",
        "      output_labels = pd.Series([eval_acc.iloc[record_index-1,-1]])\n",
        "      row = pd.concat([hyperparameters,train_loss_values,eval_loss_values,eval_acc_values,M_value,output_labels],axis=0)\n",
        "      row = row.to_frame().T\n",
        "      dataset = pd.concat([dataset,row],axis=0)\n",
        "\n",
        "    dataset.columns = dataset.columns.astype(str)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "  train_dataset = create_dataset(train_records)\n",
        "  val_dataset = create_dataset(val_records)\n",
        "  test_dataset = create_dataset(test_records)\n",
        "\n",
        "  return train_dataset,val_dataset,test_dataset\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-NZ03A_MidQ"
      },
      "source": [
        "# **Section 4 : Splitting Input-Output Data for the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fe6o49C7amiU"
      },
      "outputs": [],
      "source": [
        "def data_split(train_dataset,val_dataset,test_dataset):\n",
        "  X_train = train_dataset.iloc[:,:-1]\n",
        "  X_test = test_dataset.iloc[:,:-1]\n",
        "  X_val = val_dataset.iloc[:,:-1]\n",
        "\n",
        "  Y_train = train_dataset.iloc[:,-1]\n",
        "  Y_test = test_dataset.iloc[:,-1]\n",
        "  Y_val = val_dataset.iloc[:,-1]\n",
        "\n",
        "  return X_train,X_val,X_test,Y_train,Y_test,Y_val\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhGHvcDxM_ao"
      },
      "source": [
        "# **Section 5 : SVR Hyperparameter Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEqu1hYRImSZ"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def get_svm_hyperparameter(X_train,Y_train,X_val,Y_val):\n",
        "  best_params={}\n",
        "  lowest_mean_error=None\n",
        "  kernel = ['linear','rbf']\n",
        "  C = [0.1,1,10,100]\n",
        "\n",
        "  for k in kernel:\n",
        "    for c in C:\n",
        "      svm_regressor = svm.SVR(kernel=k,C=c)\n",
        "      svm_regressor.fit(X_train,Y_train)\n",
        "      Y_pred = svm_regressor.predict(X_val)\n",
        "      mean_error = mean_squared_error(Y_val,Y_pred)\n",
        "      if lowest_mean_error is None or mean_error < lowest_mean_error:\n",
        "              lowest_mean_error = mean_error\n",
        "              best_params = {'kernel': k, 'C': c}\n",
        "\n",
        "  return best_params\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TCWjBl1NKnD"
      },
      "source": [
        "# **Training SVM with optimal hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPXL4B92YIDo",
        "outputId": "410779e7-4a4b-4e87-aec0-9bef68bbd088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.003095184041613156\n"
          ]
        }
      ],
      "source": [
        "def svm_prediction(X_train,Y_train,X_val,Y_val,X_test,Y_test,params):\n",
        "  best_svm_regressor = svm.SVR(kernel=params['kernel'],C=params['C'])\n",
        "  combined_X = pd.concat([X_train,X_val])\n",
        "  combined_Y = pd.concat([Y_train,Y_val])\n",
        "\n",
        "  best_svm_regressor.fit(combined_X,combined_Y)\n",
        "\n",
        "  Y_pred_svm = best_svm_regressor.predict(X_test)\n",
        "  mean_error = mean_squared_error(Y_test,Y_pred_svm)\n",
        "  print(mean_error)\n",
        "\n",
        "  return best_svm_regressor,Y_pred_svm,mean_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgItByIcNSUh"
      },
      "source": [
        "# **Section 6 : RF Regressor Hyperparameter Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "iMB5gnmQnij3"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def get_rf_hyperparameter(X_train,Y_train,X_val,Y_val):\n",
        "  n_estimators = [10,50,100,200]\n",
        "  criterion = ['squared_error', 'absolute_error', 'friedman_mse', 'poisson']\n",
        "\n",
        "  best_params={}\n",
        "  lowest_mean_error=None\n",
        "\n",
        "  for n in n_estimators:\n",
        "    for c in criterion:\n",
        "      rf_regressor = RandomForestRegressor(n_estimators=n,criterion=c,random_state=42)\n",
        "      rf_regressor.fit(X_train,Y_train)\n",
        "      Y_pred = rf_regressor.predict(X_val)\n",
        "      mean_error = mean_squared_error(Y_val,Y_pred)\n",
        "\n",
        "      if lowest_mean_error is None or mean_error < lowest_mean_error:\n",
        "              lowest_mean_error = mean_error\n",
        "              best_params = {'n_estimators': n, 'criterion': c}\n",
        "\n",
        "  return best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ekfxpz8VNaaf"
      },
      "source": [
        "# **Training RF Regressor with optimal hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "collapsed": true,
        "id": "UNIsoh2MTVB5"
      },
      "outputs": [],
      "source": [
        "def rf_prediction(X_train,Y_train,X_val,Y_val,X_test,Y_test,params):\n",
        "  best_rf_regressor = RandomForestRegressor(n_estimators=params['n_estimators'],criterion=params['criterion'],random_state=42)\n",
        "  combined_X = pd.concat([X_train,X_val])\n",
        "  combined_Y = pd.concat([Y_train,Y_val])\n",
        "  best_rf_regressor.fit(combined_X,combined_Y)\n",
        "  Y_pred_rf = best_rf_regressor.predict(X_test)\n",
        "  mean_error = mean_squared_error(Y_test,Y_pred_rf)\n",
        "  print(mean_error)\n",
        "\n",
        "  return best_rf_regressor,Y_pred_rf,mean_error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxPJb17xK2qU"
      },
      "source": [
        "# **Section 7 : Training and Saving models**\n",
        "This section trains and saves the model for varying values of E - representing the first E epochs from which the data has been taken.\n",
        "\n",
        "**Naming Convention**\n",
        "\n",
        "As an example, the model for E=10 are saved as 'rf_acc_model_10'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avZF__MEvrUx"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "def train_save_models():\n",
        "  E_values = [5,10,20,30,60]\n",
        "  for e in E_values:\n",
        "    train_dataset,val_dataset,test_dataset = generate_dataset(e)\n",
        "    X_train,X_val,X_test,Y_train,Y_test,Y_val = data_split(train_dataset,val_dataset,test_dataset)\n",
        "\n",
        "    rf_params = get_rf_hyperparameter(X_train,Y_train,X_val,Y_val)\n",
        "    model,predicted_values,rf_mean_error = rf_prediction(X_train,Y_train,X_val,Y_val,X_test,Y_test,rf_params)\n",
        "    model_name = 'rf_acc_model_' + str(e)\n",
        "    joblib.dump(model,model_name)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20lvTYDLLeCW"
      },
      "source": [
        "# **Section 8 : Predictions from Saved Models**\n",
        "For each of the E values, the corresponding model is loaded and accuracy predictions and mean squared error are computed and stored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Iq3tKc6N8eji"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "predictions=[]\n",
        "error_values=[]\n",
        "E_values=[5,10,20,30,60]\n",
        "for e in E_values:\n",
        "  train_dataset,val_dataset,test_dataset = generate_dataset(e)\n",
        "  X_train,X_val,X_test,Y_train,Y_test,Y_val = data_split(train_dataset,val_dataset,test_dataset)\n",
        "  model_file = 'rf_acc_model_' + str(e)\n",
        "  loaded_model = joblib.load(model_file)\n",
        "  model_predictions = loaded_model.predict(X_test)\n",
        "  predictions.append(model_predictions)\n",
        "  error_values.append(mean_squared_error(Y_test,model_predictions))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "GwPkkeNVAZQa",
        "outputId": "320894b4-d57b-4710-c850-05a0b644d951"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"prediction_df\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"Epoch_5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07559558652993009,\n        \"min\": 0.48292599999999986,\n        \"max\": 0.7822099999999997,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.7129938805970145,\n          0.7529960000000001,\n          0.7822099999999997\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Epoch_10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0782585018010885,\n        \"min\": 0.48533999999999994,\n        \"max\": 0.7826939999999998,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.7072059999999998,\n          0.7631600000000003,\n          0.7826939999999998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Epoch_20\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08204045909383084,\n        \"min\": 0.47794,\n        \"max\": 0.7831899999999999,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.70457,\n          0.76018,\n          0.7830199999999999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Epoch_30\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08166654385034629,\n        \"min\": 0.48798,\n        \"max\": 0.7830899999999998,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.7029098009950248,\n          0.7599600000000001,\n          0.7830899999999998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Epoch_60\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08411636798199541,\n        \"min\": 0.47879999999999995,\n        \"max\": 0.7824099999999999,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.70651,\n          0.7676999999999999,\n          0.7824099999999999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"True Values\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.4534,\n        \"max\": 0.7852,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.7085,\n          0.7673,\n          0.7852\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "prediction_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-80953b00-4c08-4d65-a376-375c1110d525\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Epoch_5</th>\n",
              "      <th>Epoch_10</th>\n",
              "      <th>Epoch_20</th>\n",
              "      <th>Epoch_30</th>\n",
              "      <th>Epoch_60</th>\n",
              "      <th>True Values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.728412</td>\n",
              "      <td>0.738658</td>\n",
              "      <td>0.72837</td>\n",
              "      <td>0.72946</td>\n",
              "      <td>0.73007</td>\n",
              "      <td>0.7289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.727006</td>\n",
              "      <td>0.727136</td>\n",
              "      <td>0.72636</td>\n",
              "      <td>0.72682</td>\n",
              "      <td>0.72875</td>\n",
              "      <td>0.7331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.700672</td>\n",
              "      <td>0.698120</td>\n",
              "      <td>0.69021</td>\n",
              "      <td>0.68848</td>\n",
              "      <td>0.68565</td>\n",
              "      <td>0.6819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.678042</td>\n",
              "      <td>0.691556</td>\n",
              "      <td>0.68955</td>\n",
              "      <td>0.69064</td>\n",
              "      <td>0.68884</td>\n",
              "      <td>0.6887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.711532</td>\n",
              "      <td>0.699868</td>\n",
              "      <td>0.70360</td>\n",
              "      <td>0.70547</td>\n",
              "      <td>0.70446</td>\n",
              "      <td>0.7028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.671492</td>\n",
              "      <td>0.668214</td>\n",
              "      <td>0.67334</td>\n",
              "      <td>0.66982</td>\n",
              "      <td>0.67290</td>\n",
              "      <td>0.6647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.704708</td>\n",
              "      <td>0.701148</td>\n",
              "      <td>0.69623</td>\n",
              "      <td>0.69925</td>\n",
              "      <td>0.70182</td>\n",
              "      <td>0.7017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.720222</td>\n",
              "      <td>0.719682</td>\n",
              "      <td>0.72483</td>\n",
              "      <td>0.72480</td>\n",
              "      <td>0.72729</td>\n",
              "      <td>0.718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.634222</td>\n",
              "      <td>0.626928</td>\n",
              "      <td>0.59629</td>\n",
              "      <td>0.61204</td>\n",
              "      <td>0.61220</td>\n",
              "      <td>0.6069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.674060</td>\n",
              "      <td>0.678736</td>\n",
              "      <td>0.67987</td>\n",
              "      <td>0.68665</td>\n",
              "      <td>0.68140</td>\n",
              "      <td>0.6804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.695262</td>\n",
              "      <td>0.694172</td>\n",
              "      <td>0.68839</td>\n",
              "      <td>0.69365</td>\n",
              "      <td>0.69542</td>\n",
              "      <td>0.7004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.617538</td>\n",
              "      <td>0.626114</td>\n",
              "      <td>0.59595</td>\n",
              "      <td>0.60151</td>\n",
              "      <td>0.61445</td>\n",
              "      <td>0.6104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.658340</td>\n",
              "      <td>0.652860</td>\n",
              "      <td>0.65040</td>\n",
              "      <td>0.64490</td>\n",
              "      <td>0.64600</td>\n",
              "      <td>0.645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.712994</td>\n",
              "      <td>0.707206</td>\n",
              "      <td>0.70457</td>\n",
              "      <td>0.70291</td>\n",
              "      <td>0.70651</td>\n",
              "      <td>0.7085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.680636</td>\n",
              "      <td>0.654436</td>\n",
              "      <td>0.63433</td>\n",
              "      <td>0.63638</td>\n",
              "      <td>0.62751</td>\n",
              "      <td>0.6175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.691748</td>\n",
              "      <td>0.672682</td>\n",
              "      <td>0.66885</td>\n",
              "      <td>0.66588</td>\n",
              "      <td>0.67079</td>\n",
              "      <td>0.6714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.719160</td>\n",
              "      <td>0.719730</td>\n",
              "      <td>0.71672</td>\n",
              "      <td>0.71802</td>\n",
              "      <td>0.72065</td>\n",
              "      <td>0.7238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.603850</td>\n",
              "      <td>0.593996</td>\n",
              "      <td>0.57292</td>\n",
              "      <td>0.56302</td>\n",
              "      <td>0.55160</td>\n",
              "      <td>0.5632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.688376</td>\n",
              "      <td>0.672586</td>\n",
              "      <td>0.66119</td>\n",
              "      <td>0.67358</td>\n",
              "      <td>0.66925</td>\n",
              "      <td>0.6663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.689554</td>\n",
              "      <td>0.694258</td>\n",
              "      <td>0.70203</td>\n",
              "      <td>0.69395</td>\n",
              "      <td>0.69438</td>\n",
              "      <td>0.692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.615206</td>\n",
              "      <td>0.626528</td>\n",
              "      <td>0.58681</td>\n",
              "      <td>0.57813</td>\n",
              "      <td>0.55961</td>\n",
              "      <td>0.5714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.706252</td>\n",
              "      <td>0.703442</td>\n",
              "      <td>0.70198</td>\n",
              "      <td>0.70256</td>\n",
              "      <td>0.69978</td>\n",
              "      <td>0.7022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.766918</td>\n",
              "      <td>0.765518</td>\n",
              "      <td>0.76059</td>\n",
              "      <td>0.75616</td>\n",
              "      <td>0.75530</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.574218</td>\n",
              "      <td>0.576870</td>\n",
              "      <td>0.57531</td>\n",
              "      <td>0.57320</td>\n",
              "      <td>0.55151</td>\n",
              "      <td>0.5428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.539884</td>\n",
              "      <td>0.565566</td>\n",
              "      <td>0.56081</td>\n",
              "      <td>0.54554</td>\n",
              "      <td>0.51714</td>\n",
              "      <td>0.5724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.633718</td>\n",
              "      <td>0.614974</td>\n",
              "      <td>0.64192</td>\n",
              "      <td>0.63541</td>\n",
              "      <td>0.63056</td>\n",
              "      <td>0.6339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.754272</td>\n",
              "      <td>0.766340</td>\n",
              "      <td>0.76810</td>\n",
              "      <td>0.76542</td>\n",
              "      <td>0.76570</td>\n",
              "      <td>0.7652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.781206</td>\n",
              "      <td>0.781190</td>\n",
              "      <td>0.78122</td>\n",
              "      <td>0.78238</td>\n",
              "      <td>0.78173</td>\n",
              "      <td>0.7841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.625108</td>\n",
              "      <td>0.607616</td>\n",
              "      <td>0.61470</td>\n",
              "      <td>0.61763</td>\n",
              "      <td>0.62613</td>\n",
              "      <td>0.6266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.721378</td>\n",
              "      <td>0.714172</td>\n",
              "      <td>0.71582</td>\n",
              "      <td>0.71939</td>\n",
              "      <td>0.72197</td>\n",
              "      <td>0.7184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.782210</td>\n",
              "      <td>0.782694</td>\n",
              "      <td>0.78302</td>\n",
              "      <td>0.78309</td>\n",
              "      <td>0.78241</td>\n",
              "      <td>0.7852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.601070</td>\n",
              "      <td>0.583970</td>\n",
              "      <td>0.56612</td>\n",
              "      <td>0.57470</td>\n",
              "      <td>0.58073</td>\n",
              "      <td>0.5939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.746464</td>\n",
              "      <td>0.743984</td>\n",
              "      <td>0.74367</td>\n",
              "      <td>0.74640</td>\n",
              "      <td>0.74894</td>\n",
              "      <td>0.7464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.780874</td>\n",
              "      <td>0.780762</td>\n",
              "      <td>0.78198</td>\n",
              "      <td>0.78060</td>\n",
              "      <td>0.78199</td>\n",
              "      <td>0.7832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.606490</td>\n",
              "      <td>0.598062</td>\n",
              "      <td>0.58996</td>\n",
              "      <td>0.59333</td>\n",
              "      <td>0.59635</td>\n",
              "      <td>0.6012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.746736</td>\n",
              "      <td>0.752500</td>\n",
              "      <td>0.75569</td>\n",
              "      <td>0.75094</td>\n",
              "      <td>0.75667</td>\n",
              "      <td>0.756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.779464</td>\n",
              "      <td>0.780864</td>\n",
              "      <td>0.78319</td>\n",
              "      <td>0.78047</td>\n",
              "      <td>0.78232</td>\n",
              "      <td>0.7817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.511512</td>\n",
              "      <td>0.514162</td>\n",
              "      <td>0.53261</td>\n",
              "      <td>0.53338</td>\n",
              "      <td>0.53308</td>\n",
              "      <td>0.5301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.728040</td>\n",
              "      <td>0.728640</td>\n",
              "      <td>0.72885</td>\n",
              "      <td>0.74227</td>\n",
              "      <td>0.74162</td>\n",
              "      <td>0.7359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.752996</td>\n",
              "      <td>0.763160</td>\n",
              "      <td>0.76018</td>\n",
              "      <td>0.75996</td>\n",
              "      <td>0.76770</td>\n",
              "      <td>0.7673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.569212</td>\n",
              "      <td>0.568002</td>\n",
              "      <td>0.56347</td>\n",
              "      <td>0.55961</td>\n",
              "      <td>0.56504</td>\n",
              "      <td>0.5661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.741440</td>\n",
              "      <td>0.733046</td>\n",
              "      <td>0.74889</td>\n",
              "      <td>0.74967</td>\n",
              "      <td>0.74619</td>\n",
              "      <td>0.737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.727114</td>\n",
              "      <td>0.747854</td>\n",
              "      <td>0.76432</td>\n",
              "      <td>0.76061</td>\n",
              "      <td>0.76963</td>\n",
              "      <td>0.7669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.482926</td>\n",
              "      <td>0.485340</td>\n",
              "      <td>0.47794</td>\n",
              "      <td>0.48798</td>\n",
              "      <td>0.47880</td>\n",
              "      <td>0.4534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.711628</td>\n",
              "      <td>0.711674</td>\n",
              "      <td>0.71774</td>\n",
              "      <td>0.72040</td>\n",
              "      <td>0.72248</td>\n",
              "      <td>0.7202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.745872</td>\n",
              "      <td>0.763688</td>\n",
              "      <td>0.77366</td>\n",
              "      <td>0.77513</td>\n",
              "      <td>0.78102</td>\n",
              "      <td>0.782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.607000</td>\n",
              "      <td>0.596582</td>\n",
              "      <td>0.59945</td>\n",
              "      <td>0.60595</td>\n",
              "      <td>0.60400</td>\n",
              "      <td>0.5882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.539134</td>\n",
              "      <td>0.523092</td>\n",
              "      <td>0.52297</td>\n",
              "      <td>0.53539</td>\n",
              "      <td>0.53669</td>\n",
              "      <td>0.5526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.597362</td>\n",
              "      <td>0.564410</td>\n",
              "      <td>0.54604</td>\n",
              "      <td>0.53782</td>\n",
              "      <td>0.55204</td>\n",
              "      <td>0.5715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.579892</td>\n",
              "      <td>0.580948</td>\n",
              "      <td>0.57615</td>\n",
              "      <td>0.57767</td>\n",
              "      <td>0.58542</td>\n",
              "      <td>0.5809</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80953b00-4c08-4d65-a376-375c1110d525')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-80953b00-4c08-4d65-a376-375c1110d525 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-80953b00-4c08-4d65-a376-375c1110d525');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-814c6983-a370-4e07-a9c2-453daabff8d3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-814c6983-a370-4e07-a9c2-453daabff8d3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-814c6983-a370-4e07-a9c2-453daabff8d3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     Epoch_5  Epoch_10  Epoch_20  Epoch_30  Epoch_60 True Values\n",
              "0   0.728412  0.738658   0.72837   0.72946   0.73007      0.7289\n",
              "1   0.727006  0.727136   0.72636   0.72682   0.72875      0.7331\n",
              "2   0.700672  0.698120   0.69021   0.68848   0.68565      0.6819\n",
              "3   0.678042  0.691556   0.68955   0.69064   0.68884      0.6887\n",
              "4   0.711532  0.699868   0.70360   0.70547   0.70446      0.7028\n",
              "5   0.671492  0.668214   0.67334   0.66982   0.67290      0.6647\n",
              "6   0.704708  0.701148   0.69623   0.69925   0.70182      0.7017\n",
              "7   0.720222  0.719682   0.72483   0.72480   0.72729       0.718\n",
              "8   0.634222  0.626928   0.59629   0.61204   0.61220      0.6069\n",
              "9   0.674060  0.678736   0.67987   0.68665   0.68140      0.6804\n",
              "10  0.695262  0.694172   0.68839   0.69365   0.69542      0.7004\n",
              "11  0.617538  0.626114   0.59595   0.60151   0.61445      0.6104\n",
              "12  0.658340  0.652860   0.65040   0.64490   0.64600       0.645\n",
              "13  0.712994  0.707206   0.70457   0.70291   0.70651      0.7085\n",
              "14  0.680636  0.654436   0.63433   0.63638   0.62751      0.6175\n",
              "15  0.691748  0.672682   0.66885   0.66588   0.67079      0.6714\n",
              "16  0.719160  0.719730   0.71672   0.71802   0.72065      0.7238\n",
              "17  0.603850  0.593996   0.57292   0.56302   0.55160      0.5632\n",
              "18  0.688376  0.672586   0.66119   0.67358   0.66925      0.6663\n",
              "19  0.689554  0.694258   0.70203   0.69395   0.69438       0.692\n",
              "20  0.615206  0.626528   0.58681   0.57813   0.55961      0.5714\n",
              "21  0.706252  0.703442   0.70198   0.70256   0.69978      0.7022\n",
              "22  0.766918  0.765518   0.76059   0.75616   0.75530        0.76\n",
              "23  0.574218  0.576870   0.57531   0.57320   0.55151      0.5428\n",
              "24  0.539884  0.565566   0.56081   0.54554   0.51714      0.5724\n",
              "25  0.633718  0.614974   0.64192   0.63541   0.63056      0.6339\n",
              "26  0.754272  0.766340   0.76810   0.76542   0.76570      0.7652\n",
              "27  0.781206  0.781190   0.78122   0.78238   0.78173      0.7841\n",
              "28  0.625108  0.607616   0.61470   0.61763   0.62613      0.6266\n",
              "29  0.721378  0.714172   0.71582   0.71939   0.72197      0.7184\n",
              "30  0.782210  0.782694   0.78302   0.78309   0.78241      0.7852\n",
              "31  0.601070  0.583970   0.56612   0.57470   0.58073      0.5939\n",
              "32  0.746464  0.743984   0.74367   0.74640   0.74894      0.7464\n",
              "33  0.780874  0.780762   0.78198   0.78060   0.78199      0.7832\n",
              "34  0.606490  0.598062   0.58996   0.59333   0.59635      0.6012\n",
              "35  0.746736  0.752500   0.75569   0.75094   0.75667       0.756\n",
              "36  0.779464  0.780864   0.78319   0.78047   0.78232      0.7817\n",
              "37  0.511512  0.514162   0.53261   0.53338   0.53308      0.5301\n",
              "38  0.728040  0.728640   0.72885   0.74227   0.74162      0.7359\n",
              "39  0.752996  0.763160   0.76018   0.75996   0.76770      0.7673\n",
              "40  0.569212  0.568002   0.56347   0.55961   0.56504      0.5661\n",
              "41  0.741440  0.733046   0.74889   0.74967   0.74619       0.737\n",
              "42  0.727114  0.747854   0.76432   0.76061   0.76963      0.7669\n",
              "43  0.482926  0.485340   0.47794   0.48798   0.47880      0.4534\n",
              "44  0.711628  0.711674   0.71774   0.72040   0.72248      0.7202\n",
              "45  0.745872  0.763688   0.77366   0.77513   0.78102       0.782\n",
              "46  0.607000  0.596582   0.59945   0.60595   0.60400      0.5882\n",
              "47  0.539134  0.523092   0.52297   0.53539   0.53669      0.5526\n",
              "48  0.597362  0.564410   0.54604   0.53782   0.55204      0.5715\n",
              "49  0.579892  0.580948   0.57615   0.57767   0.58542      0.5809"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "col_names = ['Epoch_5', 'Epoch_10', 'Epoch_20','Epoch_30','Epoch_60']\n",
        "prediction_df = pd.DataFrame(predictions).T\n",
        "prediction_df.columns = col_names\n",
        "prediction_df['True Values']=Y_test.values\n",
        "\n",
        "prediction_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW3yuHo1FFR8",
        "outputId": "85e9b778-3576-49dc-fb8d-d2edeb22b4e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.0003659964948344581,\n",
              " 0.0002368833360881117,\n",
              " 0.00013052221600000062,\n",
              " 0.00012957563249830484,\n",
              " 0.00011506668472716022]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "error_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmV-0QgSLy_e"
      },
      "source": [
        "# **Saving Predictions to CSV**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "pIixo-f7Ixfk"
      },
      "outputs": [],
      "source": [
        "prediction_df.to_csv('Accuracy_predictions.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTTZpaaeJ74I"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
